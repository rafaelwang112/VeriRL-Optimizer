# ---- Lovable Cloud endpoints ----
# Return one queued job and mark it running (your Edge Function)
LOVABLE_NEXT_JOB_URL=https://waaaowaetxrxpdfrmwvm.supabase.co/functions/v1/start-optimization
# Worker status/progress callback (your Edge Function)
LOVABLE_CALLBACK_URL=https://waaaowaetxrxpdfrmwvm.supabase.co/functions/v1/eda-worker-callback

# ---- Orchestrator ----
ORCH_BASE_URL=http://orchestrator:8000

# ---- Worker behavior ----
POLL_INTERVAL_SEC=3
MAX_ITERS=10
MAX_PARALLEL=2

# ---- Design defaults (used when job doesn't provide)
DEFAULT_CLOCK_PORT=clk
DEFAULT_FREQ_MHZ=500

# ---- Paths (inside the worker container) ----
DATA_ROOT=/data/jobs
# Optional: Set a Liberty file to enable OpenSTA; leave unset to skip STA in smoke tests
# LIB_PATH=/app/tools/sky130.lib

# Optional: Hugging Face token if orchestrator proxies public API (not used directly here)
# Replace with your Hugging Face token or leave blank for local/mock mode
HF_TOKEN=REPLACE_ME_HF_TOKEN

# ---- Smoke test (no Supabase required) ----
# Enable a one-off local run. The worker will not poll LOVABLE_NEXT_JOB_URL when SMOKE_MODE=1.
# Set these values to quickly validate patch application and tool chain in docker compose.
SMOKE_MODE=0
# Top module name for smoke job
SMOKE_TOP=top
# Frequency (MHz) for smoke job (used for abc delay and fmax fallback if LIB_PATH is unset)
SMOKE_FREQ_MHZ=500
# Single-line Verilog for smoke job (avoid quotes/newlines). Example below adds a simple port.
SMOKE_VERILOG=module top(input clk); endmodule
# If set, the temporary workspace will be copied here after run for inspection
SMOKE_SAVE_DIR=/data/jobs/snapshots

# ----- FastAPI endpoints (use these for the HF worker) -----
API_BASE=http://127.0.0.1:8000
WORKER_TOKEN=local-worker-secret

# If you prefer explicit URLs instead of composing from API_BASE:
NEXT_JOB_URL=http://127.0.0.1:8000/next-queued-job
FINISH_JOB_URL=http://127.0.0.1:8000/finish-job

# ----- Hugging Face Inference API -----
HF_API_TOKEN=REPLACE_ME_HF_API_TOKEN
# Pick the model(s) you actually host on HF
HF_MODEL_DEEPSEEK=deepseek-ai/DeepSeek-Coder-V2-Instruct
HF_MODEL_MISTRAL=mistralai/Mistral-Large-Instruct

HF_TEMPERATURE=0.2
HF_MAX_NEW_TOKENS=512

# Worker loop
REQUEST_TIMEOUT_SECONDS=120
IDLE_SLEEP_SECONDS=1.2
